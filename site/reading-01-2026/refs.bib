@inproceedings{dieck22_interspeech,
  title     = {Wav2vec behind the Scenes: How end2end Models learn Phonetics},
  author    = {{Teena tom Dieck and Paula Andrea Pérez-Toro and Tomas Arias and Elmar Noeth and Philipp Klumpp}},
  year      = {{2022}},
  booktitle = {{Interspeech 2022}},
  pages     = {{5130--5134}},
  doi       = {{10.21437/Interspeech.2022-10865}},
  issn      = {{2958-1796}},
}

@inproceedings{klumpp-etal-2022-common,
    title = {{Common Phone}: A Multilingual Dataset for Robust Acoustic Modelling},
    author = "Klumpp, Philipp  and
      Arias, Tomas  and
      P{\'e}rez-Toro, Paula Andrea  and
      Noeth, Elmar  and
      Orozco-Arroyave, Juan",
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Thirteenth Language Resources and Evaluation Conference",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lrec-1.81/",
    pages = "763--768",
}

@inproceedings{wesenick94_icslp,
  title     = {{Applying speech verification to a large data base of German to obtain a statistical survey about rules of pronunciation}},
  author    = {Maria-Barbara Wesenick and Florian Schiel},
  year      = {1994},
  booktitle = {3rd International Conference on Spoken Language Processing (ICSLP 1994)},
  pages     = {279--282},
  doi       = {10.21437/ICSLP.1994-73},
  issn      = {2958-1796},
}

@ARTICLE{tian23lfmmi,
  author={Tian, Jinchuan and Yu, Jianwei and Weng, Chao and Zou, Yuexian and Yu, Dong},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Integrating Lattice-Free MMI Into End-to-End Speech Recognition}, 
  year={2023},
  volume={31},
  number={},
  pages={25-38},
  keywords={Training;Decoding;Bayes methods;Transducers;Task analysis;Speech processing;Mutual information;Automatic speech recognition;discriminative training;end-to-end;maximum mutual information;minimum Bayesian risk;sequential training},
  doi={10.1109/TASLP.2022.3198555}
}

@ARTICLE{luo2023emotionvc,
  author={Luo, Zhaojie and Lin, Shoufeng and Liu, Rui and Baba, Jun and Yoshikawa, Yuichiro and Ishiguro, Hiroshi},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Decoupling Speaker-Independent Emotions for Voice Conversion via Source-Filter Networks}, 
  year={2023},
  volume={31},
  number={},
  pages={11-24},
  keywords={Timbre;Speech processing;Acoustics;Training;Codes;Rhythm;Larynx;Auto-encoder;emotional voice conversion;prosody;source-filter networks;valence arousal},
  doi={10.1109/TASLP.2022.3190715}
}

@inproceedings{qian2020speechflow,
author = {Qian, Kaizhi and Zhang, Yang and Chang, Shiyu and Cox, David and Hasegawa-Johnson, Mark},
title = {Unsupervised speech decomposition via triple information bottleneck},
year = {2020},
publisher = {JMLR.org},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {726},
numpages = {11},
series = {ICML'20}
}

@ARTICLE{qu2024prosody2vec,
  author={Qu, Leyuan and Li, Taihao and Weber, Cornelius and Pekarek-Rosin, Theresa and Ren, Fuji and Wermter, Stefan},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Disentangling Prosody Representations With Unsupervised Speech Reconstruction}, 
  year={2024},
  volume={32},
  number={},
  pages={39-54},
  doi={10.1109/TASLP.2023.3320864}
}

@InProceedings{kurzinger2020ctc,
author="K{\"u}rzinger, Ludwig
and Winkelbauer, Dominik
and Li, Lujun
and Watzel, Tobias
and Rigoll, Gerhard",
editor="Karpov, Alexey
and Potapova, Rodmonga",
title="CTC-Segmentation of Large Corpora for German End-to-End Speech Recognition",
booktitle="Speech and Computer",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="267--278",
abstract="Recent end-to-end Automatic Speech Recognition (ASR) systems demonstrated the ability to outperform conventional hybrid DNN/HMM ASR. Aside from architectural improvements in those systems, those models grew in terms of depth, parameters and model capacity. However, these models also require more training data to achieve comparable performance.",
isbn="978-3-030-60276-5"
}

@inproceedings{wang24_asvspoof,
  title     = {ASVspoof 5: crowdsourced speech data, deepfakes, and adversarial attacks at scale},
  author    = {Xin Wang and Héctor Delgado and Hemlata Tak and Jee-weon Jung and Hye-jin Shim and Massimiliano Todisco and Ivan Kukanov and Xuechen Liu and Md Sahidullah and Tomi H. Kinnunen and Nicholas Evans and Kong Aik Lee and Junichi Yamagishi},
  year      = {2024},
  booktitle = {The Automatic Speaker Verification Spoofing Countermeasures Workshop (ASVspoof 2024)},
  pages     = {1--8},
  doi       = {10.21437/ASVspoof.2024-1},
}