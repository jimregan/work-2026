---
title: "Papers, January 2026"
bibliography: refs.bib
---

### [Wav2vec behind the Scenes: How end2end Models learn Phonetics](https://www.isca-archive.org/interspeech_2022/dieck22_interspeech.html) [@dieck22_interspeech]

### [Common Phone: A Multilingual Dataset for Robust Acoustic Modelling](https://aclanthology.org/2022.lrec-1.81/)
[@klumpp-etal-2022-common]

Dataset for acoustic models derived from Common Voice.
- [Dataset](https://zenodo.org/records/5846137)
- Languages: English, French, German, Italian, Spanish, Russian
- 116.5 hours of speech samples, collected from 11,246 speakers


### [Applying speech verification to a large data base of German to obtain a statistical survey about rules of pronunciation](https://www.isca-archive.org/icslp_1994/wesenick94_icslp.html) [@wesenick94_icslp]

- Verifies phonological rules for pronunciation variation using acoustic evidence.

### [Integrating Lattice-Free MMI Into End-to-End Speech Recognition](https://ieeexplore.ieee.org/document/9855847) [@tian23lfmmi]

- integrates LF-MMI into E2E ASR for both training and decoding
- [code](https://github.com/jctian98/e2e_lfmmi) --- no licence, espnet1-based (but not forked)

### [Decoupling Speaker-Independent Emotions for Voice Conversion via Source-Filter Networks](https://ieeexplore.ieee.org/document/9829916) [@luo2023emotionvc]
- Compares with Speechflow [@qian2020speechflow]

### [Unsupervised speech decomposition via triple information bottleneck](https://dl.acm.org/doi/10.5555/3524938.3525664) [@qian2020speechflow]
- [code](https://github.com/auspicious3000/SpeechSplit)

### [Disentangling Prosody Representations With Unsupervised Speech Reconstruction](https://ieeexplore.ieee.org/document/10269014) [@qu2024prosody2vec]
- no code

### [CTC-Segmentation of Large Corpora for German End-to-End Speech Recognition](https://link.springer.com/chapter/10.1007/978-3-030-60276-5_27) [@kurzinger2020ctc]

> (3) As these algorithms provide forced alignments, they assume that the audio contains only the text which should be aligned; but for most public domain audio this is not the case.
- [original code](https://github.com/cornerfarmer/ctc_segmentation)
- [updated code](https://github.com/lumaku/ctc-segmentation)

### [VIBEVOICE-ASR Technical Report](https://arxiv.org/abs/2601.18184)
- [code](https://github.com/microsoft/VibeVoice)

### [ASVspoof 5: crowdsourced speech data, deepfakes, and adversarial attacks at scale](https://www.isca-archive.org/asvspoof_2024/wang24_asvspoof.html) [@wang24_asvspoof]
- [code](https://github.com/asvspoof-challenge/asvspoof5) --- no licence
- [Hugging face](https://huggingface.co/datasets/jungjee/asvspoof5)
- [Zenodo](https://zenodo.org/records/14498691)
- [Kaggle](https://www.kaggle.com/datasets/ulianazb/asvspoof-2024) (D & T only, no E)